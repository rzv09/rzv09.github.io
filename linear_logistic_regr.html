<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LaTeX Notes - Raman Zatsarenko</title>
    <link rel="stylesheet" href="styles.css">
    
    <!-- MathJax for LaTeX Rendering -->
    <script type="text/javascript" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
</head>
<body style="padding: 50px; font-family: sans-serif;">
    <h1>1: Linear and Logistic Regression</h1>
    <p>One of the professors in my university said that once you figure out the math in ML,
        implementing the algorithm is pretty trivial. I tend to agree with this, and so
        let's start with some of the math here.
    </p>

    <h2>Linear Regression</h2>
    <p>
        We have \(X = [x_1, x_2, ..., x_n]^T\) observations and want to predict \(y\). We do so by modeling the data with a simple linear 
        relationship of the form \(\hat{y} = X^Tw\). The typical loss function that we employ when fitting the model is the MSE loss: \(MSE = \frac{1}{N}\sum_{i=1}^N(y_i - \hat{y_i})^2\).
        However, the choice of this loss function right off the bat can seem unmotivated. 
    </p>
    

    <p><a href="latex-notes.html">← Back to All Notes</a></p>
    <p><a href="index.html">← Back to Portfolio</a></p>
</body>
</html>
